label: "Conversation Dev Subword"
description: "Neural Conversation System Baseline Dev"

chatbot_mode: True

cell_size: 512
attn_size: 512
embedding_size: 320
bidir: True
cell_type: GRU

data_dir: data/SubLevel
max_len: 35
model_dir: models/S2S/Sub_level
max_train_size: 1000000

steps_per_checkpoint: 5000
steps_per_eval: 5000
score_function: corpus_bleu
keep_best: 5
max_to_keep: null

optimizer: adam
learning_rate: 0.0002
batch_size: 160
batch_mode: standard
read_ahead: 20
max_gradient_norm: 1.0
max_epochs: 10
learning_rate_decay_factor: 0.5
decay_every_n_epoch: 0.5

attention_type: global
final_state: last

weight_scale: 0.01

subwords: True
encoders:
  - name: message


decoders:
  - name: response

orthogonal_init: True


shared_vocab: True      # encoder and decoder will share a same vocabulary
shared_embedding: True  # encoder and decoder will share a same embedding matrix, it is not workable if shared

pervasive_dropout: True  # same dropout mask for all elements in same batch/same sequence (see Gal, 2015)
rnn_input_dropout: 0.2
rnn_output_dropout: 0.2
rnn_state_dropout: 0.2
initial_state_dropout: 0.2
word_dropout: 0.2
input_layer_dropout: 0.2
output_dropout: 0.2      # TODO
use_dropout: True
layer_norm: False